---
layout: archive
# title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

Education
======
* Ph.D in Computer Science, University of California, Santa Cruz, 2019--Now
* M.S. in Data Science, Brown University, 2018--2019  (Graduate in advance)
* B.S. in Honors Science (Mathematics and Applied Mathematics), Xi'an Jiaotong University, 2014--2018
* High school in Honors Youth (Gifted Young), Xi'an Jiaotong University, 2012--2014

Work Experience
======
Research Intern, Bytedance AI Lab (June, 2023 -- September, 2023)      
Project topic: Evaluating Hallucination of LLM Text Generation without Using Ground-Truth      
Paper 1: Measuring and Reducing LLM Hallucination without Gold-Standard Answers via Expertise-Weighting [Under Review]      
Paper 2: [Human-Instruction-Free LLM Self-Alignment with Limited Samples](https://arxiv.org/abs/2401.06785) [Under Review]

Student Researcher, Google Research Brain Team (June, 2022 -- September, 2022)               
Project topic: Class-imbalanced learing, Distributional robustness optimziation      
Paper: [Distributionally Robust Post-hoc Classifiers under Prior Shifts](https://openreview.net/forum?id=3KUfbI9_DQE)      
[First authored paper published in ICLR 2023]

Student Researcher, Google Research Brain Team (March, 2022 -- May, 2022)               
Project topic: Learning with crowd-sourced noisy labels      
Paper: [To Aggregate or Not? Learning with Separate Noisy Labels](https://arxiv.org/abs/2206.07181)      
[First authored paper published in KDD 2023]

Selected Publications
======
**Large Language Models**
1.  Measuring and Reducing LLM Hallucination without Gold-Standard Answers via Expertise-Weighting             
**Jiaheng Wei**, Yuanshun Yao, Jean-Francois Ton, Hongyi Guo, Andrew Estornell, Yang Liu                
(Under Review) [Category: LLM Evaluation; LLM Alignment; In-Context Learning; Supervised Fine-Tuning]            

2.  Human-Instruction-Free LLM Self-Alignment with Limited Samples               
Hongyi Guo, Yuanshun Yao, Wei Shen, **Jiaheng Wei**, Xiaoying Zhang, Zhaoran Wang, Yang Liu                
(Under Review) [[paper]](https://arxiv.org/abs/2401.06785) [Category: LLM Alignment; In-Context Learning]            

**Trustworthy Machine Learning**
3.  To Aggregate or Not? Learning with Separate Noisy Labels             
**Jiaheng Wei\***, Zhaowei Zhu\*, Tianyi Luo, Ehsan Amid, Abhishek Kumar, Yang Liu               
KDD -- ACM SIGKDD Conference on Knowledge Discovery and Data Mining, 2023               
[[paper]](https://dl.acm.org/doi/10.1145/3580305.3599522) [Category: Label Noise]            

4.  Distributionally Robust Post-hoc Clasifiers under Prior Shifts               
**Jiaheng Wei**, Harikrishna Narasimhan, Ehsan Amid, Wensheng Chu, Yang Liu, Abhishek Kumar               
ICLR -- International Conference on Learning Representations, 2023              
[[paper]](https://openreview.net/forum?id=3KUfbI9_DQE)  [[code]](https://github.com/weijiaheng/Drops) [Category: Long-Tailed Learning, Group-Dro] 

5.  To Smooth or Not? When Label Smoothing Meets Noisy Labels             
**Jiaheng Wei**, Hangyu Liu, Tongliang Liu, Gang Niu, Masashi Sugiyama, Yang Liu               
ICML (Long Presentation) -- International Conference on Machine Learning, 2022                
[[paper]](https://proceedings.mlr.press/v162/wei22b)  [[code]](https://github.com/UCSC-REAL/negative-label-smoothing) [Category: Label Noise]

6.	Learning with Noisy Labels Revisited: A Study Using Real-World Human Annotations           
**Jiaheng Wei\***, Zhaowei Zhu\*, Hao Cheng, Tongliang Liu, Gang Niu, Yang Liu           
ICLR -- International Conference on Learning Representations, 2022           
[[paper]](https://openreview.net/forum?id=TBWA6PLJZQm&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FAuthors%23your-submissions))  [[data]](http://noisylabels.com/)  [[code]](https://github.com/UCSC-REAL/cifar-10-100n) [Category: Label Noise]       

7.  When Optimizing f-divergence is Robust with Label Noise                 
**Jiaheng Wei** and Yang Liu            
ICLR -- International Conference on Learning Representations, 2021               
[[paper]](https://openreview.net/forum?id=WesiCoRVQ15)  [[code]](https://github.com/weijiaheng/Robust-f-divergence-measures) [Category: Label Noise]

8.  Fairness Improve Learning from Noisily Labeled Long-Tailed Data             
**Jiaheng Wei**, Zhaowei Zhu, Gang Niu, Tongliang Liu, Sijia Liu, Masashi Sugiyama, Yang Liu               
(Under Review) [[paper]](https://arxiv.org/abs/2303.12291) [Category: Long-Tailed Learning]    

**Incentives in Machine Learning**
9.	Sample Elicitation           
**Jiaheng Wei\***, Zuyue Fu*, Yang Liu, Xingyu Li, Zhuoran Yang, Zhaoran Wang           
AISTATS -- International Conference on Artificial Intelligence and Statistics, 2021           
[[paper]](https://proceedings.mlr.press/v130/wei21c)  [[code]](https://github.com/weijiaheng/Credible-sample-elicitation) [Category: Information Elicitation]

10.	Auditing for Federated Learning: A Model Elicitation Approach           
Yang Liu, Rixing Lou, **Jiaheng Wei** [Alphabetical order]
DAI -- Distributed AI, 2023               
[[paper]](https://dl.acm.org/doi/abs/10.1145/3627676.3627683) [Category: Information Elicitation]     

**Other Papers**
11.	DuelGAN: A Duel between Two Discriminators Stabilizes the GAN Training           
**Jiaheng Wei\***, Minghao Liu\*, Jiahao Luo, Andrew Zhu, James Davis, Yang Liu               
ECCV -- European Conference on Computer Vision, 2022            
[[paper]](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136830290.pdf)  [[code]](https://github.com/UCSC-REAL/DuelGAN) [Category: Deep Generative Models]           

(\*: denotes equal contributions)  


Talks
======
* **May, 2023** I gave an invited talk at [AI-Time](http://www.aitime.cn/). 

* **Apr, 2023** I gave a invited talk at the TMLR Young Scientist Seminar. 

* **Mar, 2023** I gave a short talk in the [Crowd Science workshop](https://toloka.ai/events/wsdm-2023/) at WSDM 2023. 

* **Oct, 2022** I gave an invited talk from Domain Adaptation Team at University of Toronto.

* **Aug, 2022** I gave an invited talk at [AI-Time](http://www.aitime.cn/). 

* **Jul, 2022** I gave an oral presentation at ICML 2022 (Deep Learning: Robustness). 

* **Jun, 2022** I gave an invited talk at [AI-Time](http://www.aitime.cn/). 

* **Nov, 2021** I gave a short talk in the [Weakly Supervised Learning (WSL) workshop](https://wsl-workshop.github.io/acml21.html) at ACML 2021. 
  
Conference Reviews
======
* Reviewer:            
AAAI 2020, AISTATS 2021, CVPR 2021, ICCV 2021, NeurIPS 2021, ICLR 2022, CVPR 2022, ICML 2022, IJCAI 2023, KDD 2023, TMLR, TPAMI, NeurIPS 2023, etc.

* Organizer:            
A hands-on tutorial on [learning with noisy labels](https://sites.google.com/ucsc.edu/tutorial-noisylabels/home) at IJCAI 2023.            
1st Learning and Mining with Noisy Labels Challenge at IJCAI-ECAI 2022 [[link]](http://ucsc-real.soe.ucsc.edu:1995/).

Teaching Experience
======
* Teaching Assistant at UCSC CSE 242: Machine Learning.  (Fall, 2021)      
* Teaching Assistant at UCSC CSE 290-T: Computing for Society.  (Spring, 2021)
* Teaching Assistant at UCSC CSE 142: Machine Learning.  (Spring, 2020)

Honor and Awards
======
* The only recipient of Jack Baskin and Peggy Downes-Baskin Fellowship. (2023)
* Travel Grant from International Conference on Machine Learning (ICML).  (2022)
* The First Prize of National Mount Everest Programme Scholarship in 2016-2017 Academic Year.  (2017)
* The Second Prize of National Mount Everest Programme Scholarship in 2015-2016 Academic Year.  (2016)
* The Second Prize in the 7th Chinese Mathematical Competitions.  (2016)
* Xi’an Jiaotong Siyuan Scholarship in 2015-2016 Academic Year.  (2015)
* Xi’an Jiaotong Siyuan Scholarship in 2014-2015 Academic Year.  (2014)
